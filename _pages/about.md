---
permalink: /
title: "ABOUT ME"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Computer Science PhD student at the University of Waterloo, member of the [Vector Institute](https://vectorinstitute.ai/), supervised by Professor [Pascal Poupart](https://cs.uwaterloo.ca/~ppoupart/). My research interest are broadly in alignment and post-training of LLMs with a focus on reliable and efficient machine learning algorithms. 

Previously I was a Senior Research Engineer at Huawei Noah's Ark Lab where I worked on Language Modeling, Machine Translation, Adversarial Algorithms and Model Compression. I completed my Master's degree at McGill, working on semi-supervised learning, under the supervision of Professor [Yannis Psaromiligkos](https://psaromiligkos.gitlab.io/) and Professor [Roussos Dimitrakopoulos](https://www.mcgill.ca/mining/people-0/faculty/roussos-dimitrakopoulos). I was also had the privelege to work with Professor [Luc Devroye](http://luc.devroye.org/) and we looked at some theoretical properties of deep neural networks. 

## News

* **2025** - Papers on reward guided generation [PARGS](https://arxiv.org/abs/2406.07780) and [FaRMA](https://arxiv.org/abs/2502.04517) accepted at COLM and ICML respectively
* **2024** - Paper on reliable machine learning [PreLoad](https://proceedings.mlr.press/v238/rashid24a.html) appeared at AISTATS. 
* **2023** - Awarded the Waterloo Apple PhD Fellowship for 2 years.
* **2022** -  Benchmark paper on generating realistic perturbation for evaluating dialogue model robustnes [NATURE](https://arxiv.org/abs/2111.05196) accepted at NeurIPS.
* **2021** - Published our work on adversarial data augmentation for knowledge distillation [Mate-KD](https://aclanthology.org/2021.acl-long.86/) and on [Zero-Shot Knowledge Distillation](https://aclanthology.org/2021.emnlp-main.526/) at EMNLP. 
* **2021** - Started PhD in Computer Science at University of Waterloo as a member of the Vector Institute.
* **2019** - Won the Best Paper Award at NAACL NeuralGen for our work on Bilingual text generation using GANs. 

